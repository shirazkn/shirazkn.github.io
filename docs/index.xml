<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Shiraz</title>
    <link>https://shirazkn.github.io/</link>
    <description>Recent content on Shiraz</description>
    <generator>Hugo -- 0.127.0</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 24 Mar 2024 10:43:16 -0400</lastBuildDate>
    <atom:link href="https://shirazkn.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Levi-Civita Connection</title>
      <link>https://shirazkn.github.io/posts/sphere/</link>
      <pubDate>Sun, 24 Mar 2024 10:43:16 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/sphere/</guid>
      <description>Here, I solve Problem $5-5$ from John Lee&amp;rsquo;s book on Riemannian Manifolds, which demonstrates the non-flatness of the ($2$-)sphere. This problem is particularly interesting because it serves as the motivating example for a later chapter in the book on curvature. As a by-product, we will put to rest the concerns of flat-Earthers.
Connections First, I go over the technical tools needed to state (let alone solve) the problem. A connection $\nabla$ on a smooth manifold $M$ is a way of differentiating vector fields (and more generally, tensors) along curves in $M$:</description>
    </item>
    <item>
      <title>Lie Groups as Riemannian Manifolds</title>
      <link>https://shirazkn.github.io/posts/lie-groups_calculus/</link>
      <pubDate>Tue, 30 Jan 2024 09:53:05 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/lie-groups_calculus/</guid>
      <description>A Lie group $G$ is a group that is also a (continuous, differentiable) topological space. An example to keep in mind is $G=\mathbb R^n$ which is a group under vector addition and has well-defined notions of continuity and differentiation. To measure lengths and volumes (and relatedly, to define and integrate probability densities) we need to endow $G$ with additional structure so that it is not merely a manifold, but a Riemannian manifold.</description>
    </item>
    <item>
      <title>Lie Groups: Construction and Geometry</title>
      <link>https://shirazkn.github.io/posts/lie-groups_construction/</link>
      <pubDate>Wed, 24 Jan 2024 14:20:59 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/lie-groups_construction/</guid>
      <description>There are multiple ways to construct new groups from old ones. For instance, the semidirect product $SO(3) \ltimes \mathbb R^3$ is the Special Euclidean group $SE(3)$, which is composed of all the rigid transformations of $\mathbb R^3$ (minus reflections). Here, I provide an intuition for how these constructions work. I will also go over some of the additional structures that can be imposed on Lie groups, paving the path towards doing differential geometry and calculus on Lie groups.</description>
    </item>
    <item>
      <title>The Lie Group-Lie Algebra Correspondence</title>
      <link>https://shirazkn.github.io/posts/lie-groups/</link>
      <pubDate>Mon, 15 Jan 2024 07:24:59 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/lie-groups/</guid>
      <description>A topological group is a set of elements $G$ that has both a group operation $\odot$ and a topology . The group operation satisfies the usual axioms (same as those of finite groups ), and the presence of a topology lets us say things like &amp;rsquo;the group is connected&amp;rsquo; and &amp;rsquo;the group operation is continuous&amp;rsquo;. $G$ is called a Lie group if it is also a smooth manifold. The smooth structure of the manifold must be compatible with the group operation in the following sense: $\odot$ is differentiable with respect to either of its arguments 1.</description>
    </item>
    <item>
      <title>Vector Fields on Manifolds</title>
      <link>https://shirazkn.github.io/posts/differential-forms/</link>
      <pubDate>Wed, 03 Jan 2024 11:22:28 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/differential-forms/</guid>
      <description>Over the past year, I have struggled to pin down what the scope of my blog should be. There is plenty of exposition out there on just about every aspect of modern mathematics, but especially on exterior calculus and differential geometry due to their situation at the intersection of several areas in theoretical and applied mathematics. (As a case in point, the two main references that I&amp;rsquo;ve been using to self-learn differential forms were the creations of a theoretical physicist and a computer scientist , respectively).</description>
    </item>
    <item>
      <title>Fourier Transforms of Periodic Functions</title>
      <link>https://shirazkn.github.io/posts/fourier/</link>
      <pubDate>Mon, 02 Oct 2023 14:59:15 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/fourier/</guid>
      <description>The Fourier transform takes a (absolutely integrable) function $f:\mathbb R \rightarrow \mathbb R$ and outputs a different (possibly complex-valued) function. If the first is interpreted as a signal (e.g., the waveform of an audio that is parameterized by time), then its Fourier transform has its &amp;lsquo;peaks&amp;rsquo; at the dominant frequencies of the signal. I will not expound too much on the Fourier transform itself, but its computation looks something like this1:</description>
    </item>
    <item>
      <title>Matrix Multiplication</title>
      <link>https://shirazkn.github.io/posts/matrix/</link>
      <pubDate>Sun, 28 May 2023 10:35:07 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/matrix/</guid>
      <description>In this post, I want to bridge the gap between abstract vector spaces (which are the mathematical foundation of linear algebra) and matrix multiplication (which is the linear algebra most of us are familiar with). To do this, we will restrict ourselves to a specific example of a vector space &amp;ndash; the Euclidean space. Unlike the typical 101 course in linear algebra, I will avoid talking about solving systems of equations in this post.</description>
    </item>
    <item>
      <title>What is a Vector?</title>
      <link>https://shirazkn.github.io/posts/vector/</link>
      <pubDate>Sat, 20 May 2023 15:26:18 -0700</pubDate>
      <guid>https://shirazkn.github.io/posts/vector/</guid>
      <description>A running gag in engineering colleges is that a lot of instructors begin their first class of the semester with this question: &amp;ldquo;What is a vector?&amp;rdquo;. I used to find this ritual almost pointless because to me, every answer to this question felt either like a non-answer or a matter of context. I mean it depends, right? A structural engineer should have a different answer to this question than, say, a data scientist.</description>
    </item>
    <item>
      <title>Understanding Sparsity through Sub-Gradients</title>
      <link>https://shirazkn.github.io/posts/sparsity_2/</link>
      <pubDate>Fri, 28 Apr 2023 17:15:26 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/sparsity_2/</guid>
      <description>&lt;!-- This post will require some familiarity with optimization (or least-squares, if you will). --&gt;
&lt;p&gt;&lt;a href=&#34;https://shirazkn.github.io/posts/sparsity&#34; class=&#34;accented&#34;&gt;
    We talked about
&lt;/a&gt; why sparsity plays an important role in many of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Inverse_problem&#34; target=&#34;_blank&#34; class=&#34;accented&#34;&gt;
    inverse problems
&lt;/a&gt; that we encounter in engineering. To actually find the sparse solutions to these problems, we add &amp;lsquo;sparsity-promoting&amp;rsquo; terms to our optimization problems; the machine learning community calls this approach &lt;em&gt;regularization&lt;/em&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sparsity</title>
      <link>https://shirazkn.github.io/posts/sparsity/</link>
      <pubDate>Sat, 22 Apr 2023 11:05:58 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/sparsity/</guid>
      <description>The so called curse of dimensionality in machine learning is the observation that neural networks with many parameters can be impossibly difficult to train due to the vastness of its parameter space. Another issue that arises in practice is that most of the neural network does not do anything, as a lot of its weights turn out to be redundant. This is because many (if not all) of the problems we&amp;rsquo;re interested in solving as engineers have some inherent sparsity.</description>
    </item>
    <item>
      <title>Hilbert Spaces</title>
      <link>https://shirazkn.github.io/posts/hilbert-spaces/</link>
      <pubDate>Fri, 21 Apr 2023 12:09:09 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/hilbert-spaces/</guid>
      <description>Let $\mathcal X$ be a Hilbert space, which means that it is a vector space that has an inner product (denoted by $\langle \cdot, \cdot\rangle _\mathcal X$) and that it is complete, i.e., it doesn&amp;rsquo;t have er&amp;hellip; holes in it. Recall that inner product spaces have a rich geometric structure, and so do Hilbert spaces. The Euclidean space $\mathbb R^n$ is an obvious example, where the inner product is just the dot product.</description>
    </item>
    <item>
      <title>Norm Balls</title>
      <link>https://shirazkn.github.io/posts/balls/</link>
      <pubDate>Tue, 18 Apr 2023 21:32:10 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/balls/</guid>
      <description>&lt;p&gt;Let&amp;rsquo;s look at the norm balls corresponding to the different $p$-norms in $\mathbb R^n$, where $n$ is the dimension of the space. For a vector $v\in \mathbb R^n$, the $p$-norm is&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Real World is a Special Case</title>
      <link>https://shirazkn.github.io/posts/pythagoras/</link>
      <pubDate>Fri, 14 Apr 2023 15:53:46 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/pythagoras/</guid>
      <description>The title is a quote from this math podcast . I mentioned in the last post that Euclidean geometry arises as a special case of the geometry of inner product spaces. And yet, the only spaces that are &amp;rsquo;tangible&amp;rsquo; to us humans are the $1$, $2$, and $3$ dimensional Euclidean spaces. No other inner product spaces feel nearly as intuitive.
In this post I&amp;rsquo;m showing how the Pythagoras theorem is a special case of a more general feature of inner product spaces.</description>
    </item>
    <item>
      <title>Norms, Metrics, and Inner Products</title>
      <link>https://shirazkn.github.io/posts/norms_metrics/</link>
      <pubDate>Mon, 10 Apr 2023 12:20:23 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/norms_metrics/</guid>
      <description>This is an explainer on norms, metrics, and inner products, and their relationships to each other.
Norms A norm is any real-valued function $\lVert{}\cdot{}\rVert$ (taking the elements of a corresponding vector space as its arguments), which has the following properties:
It is nonnegative, and $0$ only at the &amp;lsquo;zero element&amp;rsquo; (for e.g., at the origin of $\mathbb R^n$).
$\lVert \alpha x \rVert = |\alpha| \lVert x \rVert$ for any scalar $\alpha$.</description>
    </item>
    <item>
      <title>The Unreasonable Effectiveness of $2$ in Statistics</title>
      <link>https://shirazkn.github.io/posts/leastsquares/</link>
      <pubDate>Sun, 09 Apr 2023 12:20:39 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/leastsquares/</guid>
      <description>First off, this is a reference to The Unreasonable Effectiveness of Mathematics in the Natural Sciences , a very popular paper by Eugene Wigner which explores how mathematics is unreasonably effective at not only explaining, but also predicting scientific phenomena. I had a similar question about the number $2$ which repeatedly shows up in engineering and science, specifically in the form of the $2$-norm of a vector, and seems surprisingly effective at doing what it&amp;rsquo;s supposed to do.</description>
    </item>
    <item>
      <title>Cat Theory 😼</title>
      <link>https://shirazkn.github.io/posts/cat_theory_1/</link>
      <pubDate>Sat, 18 Mar 2023 21:07:38 -0400</pubDate>
      <guid>https://shirazkn.github.io/posts/cat_theory_1/</guid>
      <description>One of my motivations for starting a blog was Eugenia Cheng&amp;rsquo;s book The Joy of Abstraction 1. It&amp;rsquo;s a surprisingly accessible, gentle introduction to category theory, a topic that is usually only taught to graduate students in math. She compiled part of the book using notes from the category theory class that she teaches at the Art Institute of Chicago, a testament to the aesthetic appreciation that one can expect to gain of category theory irrespective of their academic background.</description>
    </item>
    <item>
      <title>The Incompleteness Theorems</title>
      <link>https://shirazkn.github.io/posts/language_and_logic2/</link>
      <pubDate>Sun, 05 Feb 2023 08:46:18 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/language_and_logic2/</guid>
      <description>In my earlier post I suggested that there is no objective notion of logical truth, that whether a statement is &amp;rsquo;true&amp;rsquo; can depend on the system of truth that one is operating in. Here we will develop that argument further using the concept of axiomatic systems. This is a long one, but I&amp;rsquo;m excited to talk about it!
Axiomatic Systems An axiomatization is an assignment of rules (axioms) such as &amp;ldquo;one plus one equals two,&amp;rdquo; making up an axiomatic system or a formal system.</description>
    </item>
    <item>
      <title>Misuse as a Use of Language</title>
      <link>https://shirazkn.github.io/posts/language_and_logic1/</link>
      <pubDate>Fri, 27 Jan 2023 13:48:49 -0500</pubDate>
      <guid>https://shirazkn.github.io/posts/language_and_logic1/</guid>
      <description>This is my first post! It discusses the question of whether spoken and written languages like English could be &amp;rsquo;logical&amp;rsquo; by design. I will break this post up into two parts. The first one does not require a mathematical background whatsoever, whereas the second touches on the concepts of axioms, theorems and proofs.
Fallacies The word logic as it is used in everyday parlance refers to informal logic (as opposed to formal logic , which is instead a rigorous mathematical construct).</description>
    </item>
  </channel>
</rss>
