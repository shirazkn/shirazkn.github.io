---
title: "Decategorification of Music, Math, and the Human Condition"
date: 2023-08-13T10:27:23-04:00
draft: true
---

I promise you that *decategorification*, a word whose conception is attributed to John Baez, means the opposite of what it sounds like. What it sounds like is that we're picking objects out of a *category* and examining what it is; what it really means is that we treat objects that are somewhat equal (in a certain sense) as being equal. When someone says `red', if inside your head flash images of apples, traffic lights, and blood in quick succession, then you have decategorified the notion of `red'. Similarly, `$2$' is the decategorification of everything that occurs or exists in a pair: birds (sometimes), socks (if you do your laundry right), hands (in most people). I guess what we're really doing is `categorizing' these concepts into the `category' `$2$', but oh well.

<!-- Category theory is a branch of math that constructs a common type of object, called a *category*, for each type of object. This allows us to learn new things in one category, and apply it to another. We do this all the time. 

In the category of sets, isomorphic  -->

Isomorphic objects are those that have an *isomorphism* between them, which in turn implies that they 'have the same form'; *iso* means same, and *morphism* means form. An isomorphism allows us to go back and forth between the objects without ambiguity, whereas a *homomorphism* only allows us to go in one direction (usually because it forgets or ignores some of the information about the source object).

The act of taking a photograph is a homomorphism from a person to an image of them. We can take photographs of people, but we can't use (a single) photograph to reconstruct the person, even just a $3D$ model of them. This is because we've forgotten their depth; maybe they have a tail on their bottom, and the photograph was taken from the front so that we may never know. We can *infer* that they do not, as with most humans, have a tail. This is what humans do in engineering to `fill in the gaps', and it's what AI does. The human capability of inference comes from our lived and taught experiences, as well as genetic and evolutionary predispositions. AI scrapes the internet.

An isomorphism allows us to go both ways. An MRI scan is (if we choose to squint at its blemishes) an isomorphism between the physical characteristics of human brain and a digital representation of it. Note that I said isomorphism *between* (and homomorphism *from*) to emphasize the symmetry (and asymmetry) of these concepts.